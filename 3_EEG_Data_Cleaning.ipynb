{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy import interpolate\n",
    "import pickle\n",
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:15: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "\n",
    "######################### Read eeg data ##########################\n",
    "\n",
    "eeg_data=pd.read_csv(\"D:/Projects/Prognostic Predictions/ML analysis/20+ trends for manuscript_(2019-07-17T18.13.11.597)/output_all_long_472.csv\",\n",
    "                     skiprows=0,na_values=[\"N/A\",\"Insuff. Data\"])\n",
    "eeg_data.columns=[i.replace(\" \",\"_\")for i in eeg_data.columns]\n",
    "Timebins=12\n",
    "eeg_data=eeg_data[eeg_data[\"Timebins\"]<=Timebins]\n",
    "\n",
    "# Timebins=48\n",
    "\n",
    "##### Creating flags to distinguish between Nas in the middle and ones towards the end #######\n",
    "\n",
    "eeg_data=eeg_data.astype({\"Timebins\":\"object\"},copy=False)  # changing type of Timebins so that it isnt agg in the next step\n",
    "\n",
    "temp1=eeg_data.sort_values(by=[\"PID\",\"Timebins\"], ascending=False).groupby([\"PID\"])[\"PID\",\"Timebins\",\"Alpha_sum\"]\\\n",
    "                       .rolling(min_periods=1, on=\"Timebins\",window=48).sum().reset_index()  # After this step Nas remaining will be the ones towards end\n",
    "\n",
    "temp1.iloc[:,3:]=temp1.iloc[:,3:].apply(lambda x : x.isna()) #Flagging those Nas as True \n",
    "temp1.rename(columns={\"Alpha_sum\":\"Na_rows\"},inplace=True) \n",
    "temp1.drop(columns=\"level_1\",inplace=True)\n",
    "\n",
    "##### Merging with the original data to get the Na_rows flag #######\n",
    "\n",
    "eeg_data=eeg_data.merge(temp1,\"inner\",on=[\"PID\",\"Timebins\"],suffixes=(\"\",\"_flag\"))\n",
    "eeg_data=eeg_data.astype({\"Timebins\":\"int\"},copy=False) ## Changing timebins back to int\n",
    "\n",
    "##### Removing rows where less than 4 values are present #######\n",
    "\n",
    "eeg_row_flag=eeg_data.groupby([\"PID\"])[\"Alpha_sum\"].agg([\"count\"])\n",
    "eeg_row_flag=eeg_row_flag[eeg_row_flag[\"count\"]>4]\n",
    "eeg_data=eeg_data.merge(eeg_row_flag,'inner',on=\"PID\")\n",
    "eeg_data.drop(columns=\"count\",inplace=True)\n",
    "# eeg_data=eeg_data.merge(eeg_data.groupby([\"PID\"])[\"Timestamp\"].min().reset_index()\n",
    "# ,\"inner\",on=[\"PID\"],suffixes=(\"\",\"_start_Timestamp\"))\n",
    "# eeg_data.drop(columns=\"Timestamp\",inplace=True)\n",
    "eeg_data.drop(columns=\"Na_rows\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### Data Interpolation ##########################\n",
    "\n",
    "######################### Interpolation through cubic spline ##########################\n",
    "\n",
    "arr_to_interpol=eeg_data.iloc[:,2:].values  #selecting columns other than  PID and Timestamp\n",
    "for i in range(0,int(len(eeg_data)/Timebins)):\n",
    "    for j in range(1,int(arr_to_interpol.shape[1])):\n",
    "        idx_finite = np.isfinite(arr_to_interpol[i*Timebins:(i+1)*Timebins,j])\n",
    "        transformer=interpolate.splrep(arr_to_interpol[i*Timebins:(i+1)*Timebins,0][idx_finite],arr_to_interpol[i*Timebins:(i+1)*Timebins,j][idx_finite],k=2)\n",
    "        arr_to_interpol[i*Timebins:(i+1)*Timebins,j]=interpolate.splev(arr_to_interpol[i*Timebins:(i+1)*Timebins,0],transformer)\n",
    "\n",
    "eeg_data_quadratic_spline=eeg_data.copy(deep=True)\n",
    "eeg_data_quadratic_spline.iloc[:,3:]=arr_to_interpol[:,1:] # Transfering back the interpolated data\n",
    "\n",
    "# We keep the spline for the Nas that appear in between records and build multiple\n",
    "# datasets using other methods for the Nas that appear in the end\n",
    "\n",
    "######################### Interpolation through hot deck ##########################\n",
    "\n",
    "eeg_data_hot_deck=pd.DataFrame().reindex_like(eeg_data)\n",
    "for i in eeg_data.columns:\n",
    "    eeg_data_hot_deck[i] = eeg_data.groupby(\"PID\")[i].apply(lambda x : x.fillna(method='ffill'))\n",
    "\n",
    "\n",
    "######################### Interpolation through Random hot deck ##########################\n",
    "\n",
    "eeg_data_random_hot_deck=pd.DataFrame().reindex_like(eeg_data)\n",
    "for i in eeg_data.columns:\n",
    "    eeg_data_random_hot_deck[i] = eeg_data.groupby(\"PID\")[i].apply(lambda x : x.fillna(pd.Series(\n",
    "        np.random.choice(x[x.isna()==False], size=len(eeg_data.index)))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing the timeseries data for rnns\n",
    "pickle_file=\"D:/Projects/Prognostic Predictions/Proccessed data/EEG_time_series_data.pickle\"\n",
    "pickle.dump( [eeg_data_quadratic_spline,eeg_data_random_hot_deck], open(pickle_file, \"wb\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_smooth=set(eeg_data_quadratic_spline.columns)-set([\"Timestamp\"])\n",
    "eeg_data_quadratic_spline_smoothed=eeg_data_quadratic_spline.groupby([\"PID\"])[list(columns_to_smooth)]\\\n",
    "                       .rolling(min_periods=1, on=\"Timebins\",window=4).mean().reset_index().drop(columns=[\"level_1\"])\n",
    "eeg_data_hot_deck_smoothed=eeg_data_hot_deck.groupby([\"PID\"])[list(columns_to_smooth)]\\\n",
    "                       .rolling(min_periods=1, on=\"Timebins\",window=4).mean().reset_index().drop(columns=[\"level_1\"])\n",
    "eeg_data_random_hot_deck_smoothed=eeg_data_random_hot_deck.groupby([\"PID\"])[list(columns_to_smooth)]\\\n",
    "                       .rolling(min_periods=1, on=\"Timebins\",window=4).mean().reset_index().drop(columns=[\"level_1\"])\n",
    "\n",
    "# eeg_data_quadratic_spline=eeg_data_quadratic_spline[[\"PID\",\"Timebins\",\"Timestamp\"]].merge(eeg_data_quadratic_spline_smoothed,\"inner\",on=[\"PID\",\"Timebins\"],)\n",
    "# eeg_data_hot_deck=eeg_data_hot_deck[[\"PID\",\"Timebins\",\"Timestamp\"]].merge(eeg_data_hot_deck_smoothed,\"inner\",on=[\"PID\",\"Timebins\"])\n",
    "# eeg_data_random_hot_deck=eeg_data_random_hot_deck[[\"PID\",\"Timebins\",\"Timestamp\"]].merge(eeg_data_random_hot_deck_smoothed,\"inner\",on=[\"PID\",\"Timebins\"])\n",
    "\n",
    "eeg_data_quadratic_spline=eeg_data_quadratic_spline_smoothed\n",
    "eeg_data_hot_deck=eeg_data_hot_deck_smoothed\n",
    "eeg_data_random_hot_deck=eeg_data_random_hot_deck_smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### Pivoting the data ##########################\n",
    "\n",
    "######################### quadratic spline dataset ##########################\n",
    "\n",
    "eeg_data_quadratic_spline=eeg_data_quadratic_spline.set_index([\"PID\",\"Timebins\"]).unstack()\n",
    "eeg_data_quadratic_spline.columns=[str(i[0])+str(i[1]) for i in eeg_data_quadratic_spline.columns]\n",
    "eeg_data_quadratic_spline.drop(columns=eeg_data_quadratic_spline.columns[1:48],inplace=True)\n",
    "eeg_data_quadratic_spline=eeg_data_quadratic_spline.reset_index()\n",
    "\n",
    "######################### hot deck dataset ##########################\n",
    "\n",
    "eeg_data_hot_deck=eeg_data_hot_deck.set_index([\"PID\",\"Timebins\"]).unstack()\n",
    "eeg_data_hot_deck.columns=[str(i[0])+str(i[1]) for i in eeg_data_hot_deck.columns]\n",
    "eeg_data_hot_deck.drop(columns=eeg_data_hot_deck.columns[1:48],inplace=True)\n",
    "eeg_data_hot_deck=eeg_data_hot_deck.reset_index()\n",
    "\n",
    "######################### Random hot deck dataset ##########################\n",
    "\n",
    "eeg_data_random_hot_deck=eeg_data_random_hot_deck.set_index([\"PID\",\"Timebins\"]).unstack()\n",
    "eeg_data_random_hot_deck.columns=[str(i[0])+str(i[1]) for i in eeg_data_random_hot_deck.columns]\n",
    "eeg_data_random_hot_deck.drop(columns=eeg_data_random_hot_deck.columns[1:48],inplace=True)\n",
    "eeg_data_random_hot_deck=eeg_data_random_hot_deck.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_from_seconds_data=pickle.load( open(\\\n",
    "    \"D:/Projects/Prognostic Predictions/Proccessed data/EEG_data_SECONDS_with aditional_features.pickle\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_data_quadratic_spline=eeg_data_quadratic_spline.merge(features_from_seconds_data,on=\"PID\")\n",
    "eeg_data_hot_deck=eeg_data_random_hot_deck.merge(features_from_seconds_data,on=\"PID\")\n",
    "eeg_data_random_hot_deck=eeg_data_random_hot_deck.merge(features_from_seconds_data,on=\"PID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file=\"D:/Projects/Prognostic Predictions/Proccessed data/EEG_data.pickle\"\n",
    "pickle.dump( [eeg_data_quadratic_spline, eeg_data_hot_deck, eeg_data_random_hot_deck], open(pickle_file, \"wb\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_timestamp=eeg_data.groupby(\"PID\")[\"Timestamp\"].max().reset_index()\n",
    "patient_timestamp['Timestamp']=pd.to_datetime(patient_timestamp['Timestamp'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "patient_timestamp['Timestamp'] = (patient_timestamp.Timestamp.dt.tz_convert('US/Eastern').dt\n",
    "                        .strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file=\"D:/Projects/Prognostic Predictions/Proccessed data/patient_timestamp.pickle\"\n",
    "pickle.dump( patient_timestamp, open(pickle_file, \"wb\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
