{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy import interpolate\n",
    "import pickle\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### Read eeg data ##########################\n",
    "\n",
    "# Enter the EEG second by second data location\n",
    "EEG_DATA_LOCATION=\"D:/Projects/Prognostic Predictions/Data/second by second data/High res aEEG_(2020-06-01T09.23.27.972)/output_all_long_502second by second.csv\"\n",
    "eeg_data=pd.read_csv(EEG_DATA_LOCATION,\n",
    "                     skiprows=0,na_values=[\"N/A\",\"Insuff. Data\"])\n",
    "eeg_data.columns=[i.replace(\" \",\"_\")for i in eeg_data.columns]\n",
    "# eeg_data=eeg_data[eeg_data[\"Timebins\"]<=10]\n",
    "Timebins=21600\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "eeg_data=eeg_data.astype({\"Timebins\":\"object\"},copy=False)  # changing type of Timebins so that it isnt agg in the next step\n",
    "temp1=eeg_data.sort_values(by=[\"PID\",\"Timebins\"], ascending=False).groupby([\"PID\"])[\"PID\",\"Timebins\",\"aEEG\"]\\\n",
    "                       .rolling(min_periods=1, on=\"Timebins\",window=21600).sum().reset_index()  # After this step Nas remaining will be the ones towards end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1.iloc[:,3:]=temp1.iloc[:,3:].apply(lambda x : x.isna()) #Flagging those Nas as True \n",
    "temp1.rename(columns={\"aEEG\":\"Na_rows\"},inplace=True) \n",
    "temp1.drop(columns=\"level_1\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_data=eeg_data.merge(temp1,\"inner\",on=[\"PID\",\"Timebins\"],suffixes=(\"\",\"_flag\"))\n",
    "eeg_data=eeg_data.astype({\"Timebins\":\"int\"},copy=False) ## Changing timebins back to int\n",
    "\n",
    "##### Removing rows where less than 4 values are present #######\n",
    "\n",
    "eeg_row_flag=eeg_data.groupby([\"PID\"])[\"aEEG\"].agg([\"count\"])\n",
    "eeg_row_flag=eeg_row_flag[eeg_row_flag[\"count\"]>4]\n",
    "eeg_data=eeg_data.merge(eeg_row_flag,'inner',on=\"PID\")\n",
    "eeg_data.drop(columns=\"count\",inplace=True)\n",
    "# eeg_data.drop(columns=\"Na_rows\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_to_interpol=eeg_data.iloc[:,2:4].values  #selecting columns other than  PID and Timestamp\n",
    "for i in range(0,int(len(eeg_data)/Timebins)):\n",
    "    for j in range(1,int(arr_to_interpol.shape[1])):\n",
    "        idx_finite = np.isfinite(arr_to_interpol[i*Timebins:(i+1)*Timebins,j])\n",
    "        transformer=interpolate.splrep(arr_to_interpol[i*Timebins:(i+1)*Timebins,0][idx_finite],arr_to_interpol[i*Timebins:(i+1)*Timebins,j][idx_finite],k=2)\n",
    "        arr_to_interpol[i*Timebins:(i+1)*Timebins,j]=interpolate.splev(arr_to_interpol[i*Timebins:(i+1)*Timebins,0],transformer)\n",
    "\n",
    "eeg_data_quadratic_spline=eeg_data.copy(deep=True)\n",
    "eeg_data_quadratic_spline.iloc[:,3:4]=arr_to_interpol[:,1:] # Transfering back the interpolated data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_data_quadratic_spline_with_zeros=eeg_data_quadratic_spline.copy()\n",
    "eeg_data_quadratic_spline_with_zeros.loc[eeg_data_quadratic_spline_with_zeros[\"Na_rows\"]==True,\"aEEG\"]=0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_time_invariant_data=pickle.load( open(\\\n",
    "    \"D:/Projects/Prognostic Predictions/Proccessed data/Time_Invariant_data.pickle\", \"rb\" ) )\n",
    "\n",
    "# processed_time_invariant_data=pd.concat((train_data,test_data),axis=0)\n",
    "processed_data=processed_time_invariant_data[[\"PID\",\"outcome\"]].merge(eeg_data_quadratic_spline[[\"PID\",\"Timebins\",\"aEEG\"]],on=\"PID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_array=processed_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creating a variable slope feature to capture the slope between current and next record\n",
    "slope_feature=np.abs(np.arctan((np.concatenate((processed_data_array[1:,3],np.array([0])))-processed_data_array[:,3]).astype('float'))*180/3.14)\n",
    "# changing the last record of each patient to nan since the next record is not present\n",
    "slope_feature[21599::21600]=np.nan                          \n",
    "# combining as a new feature with the data set\n",
    "processed_data_array=np.concatenate((processed_data_array,slope_feature.reshape(-1,1)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:13: RuntimeWarning: invalid value encountered in greater\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "SECONDS=3600  ### variable controls the level of aggregation\n",
    "processed_data_with_features=np.empty((int(processed_data_array.shape[0]/SECONDS),5),dtype='O')\n",
    "for i in range(int(len(processed_data_array)/SECONDS)):\n",
    "#     PID\n",
    "    processed_data_with_features[i,0]=processed_data_array[i*SECONDS,0]\n",
    "#     Timebins\n",
    "    processed_data_with_features[i,1]=np.floor((processed_data_array[i*SECONDS,2]-1)/SECONDS)+1\n",
    "#     points above 1.5*median\n",
    "    processed_data_with_features[i,2]=np.count_nonzero(processed_data_array[i*SECONDS:(i+1)*SECONDS,3]>np.median(processed_data_array[i*SECONDS:(i+1)*SECONDS,3])*1.5)/SECONDS    \n",
    "#     points above 1.5*mean\n",
    "    processed_data_with_features[i,3]=np.count_nonzero(processed_data_array[i*SECONDS:(i+1)*SECONDS,3]>np.mean(processed_data_array[i*SECONDS:(i+1)*SECONDS,3])*1.5)/SECONDS    \n",
    "#     points with slope greated than 85\n",
    "    processed_data_with_features[i,4]=np.count_nonzero(processed_data_array[i*SECONDS:(i+1)*SECONDS,4]>75)/SECONDS        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting to a pandas data frame\n",
    "processed_data_with_features=pd.DataFrame(processed_data_with_features,columns=['PID','Timebins','percent_above_1.5*median','percent_above_1.5*mean','steep_slopes'])\n",
    "# Pivioting the data\n",
    "processed_data_with_features=processed_data_with_features.set_index([\"PID\",\"Timebins\"]).unstack()\n",
    "processed_data_with_features.columns=[str(i[0])+str(i[1]) for i in processed_data_with_features.columns]\n",
    "processed_data_with_features=processed_data_with_features.reset_index()\n",
    "\n",
    "for i in processed_data_with_features.columns:\n",
    "    if i!=\"PID\":\n",
    "        processed_data_with_features[i]=processed_data_with_features[i].astype(\"float\")\n",
    "\n",
    "# storing as a picle file\n",
    "pickle_file=\"D:/Projects/Prognostic Predictions/Proccessed data/EEG_data_SECONDS_with aditional_features.pickle\"\n",
    "pickle.dump( processed_data_with_features, open(pickle_file, \"wb\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
